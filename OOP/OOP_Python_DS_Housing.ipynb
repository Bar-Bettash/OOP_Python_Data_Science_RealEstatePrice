{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fdd0de",
   "metadata": {},
   "source": [
    "### First, Technical Terms and Definitions\n",
    "\n",
    "* __Base class:__ A class that defines common properties and methods for other classes. In this case, DataProcessor is the base class.\n",
    "\n",
    "* __Derived class:__ A class that inherits properties and methods from another class. HousingDataProcessor is a derived class of DataProcessor.\n",
    "\n",
    "* __Feature engineering:__ The process of creating new features from existing data to improve model performance.\n",
    "\n",
    "* __One-hot encoding:__ A technique to represent categorical variables as numerical features by creating binary columns for each category.\n",
    "\n",
    "* __Random Forest:__ An ensemble machine learning algorithm that combines multiple decision trees to make predictions.\n",
    "\n",
    "* __Standardization:__ A preprocessing technique that scales numerical features to have a mean of 0 and a standard deviation of 1.\n",
    "Feature importance: A measure of how important each feature is in predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706dc9b",
   "metadata": {},
   "source": [
    "### Import Libraries and Load Data\n",
    "In this step, we import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77793e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede175e4",
   "metadata": {},
   "source": [
    "### Object-Oriented Programming (OOP)\n",
    "Define DataProcessor (base class).\n",
    "It serves as a blueprint for creating objects that handle data processing tasks.\n",
    "* __init__ (self, data_path): This is the constructor method, called when creating a new DataProcessor object. It takes the data path (location of the CSV file) as input and:\n",
    "\n",
    "* Reads the CSV file using pd.read_csv and stores it in the self.data attribute.\n",
    "\n",
    "* Initializes self.X and self.y to None as placeholders for features and target variables later.\n",
    "\n",
    "* clean_data(self): This method removes rows with missing values (NaN) from the data using self.data.dropna(inplace=True).\n",
    "\n",
    "* split_features_target(self, target_column): This method separates features (independent variables) from the target variable (dependent variable). It takes the target column name as input and:\n",
    "\n",
    "* Drops the target column from the data using self.data.drop and stores the remaining features in self.X.\n",
    "\n",
    "* Extracts the target column and stores it in self.y.\n",
    "\n",
    "* __@staticmethod__: This decorator defines a static method called log_transform that doesn't require creating an object of the class. It takes a value as input and performs a log transformation using np.log(value + 1). This is useful for handling skewed numerical features in housing data (e.g., number of bedrooms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a08c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, data_path):\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def clean_data(self):\n",
    "        self.data.dropna(inplace=True)\n",
    "\n",
    "    def split_features_target(self, target_column):\n",
    "        self.X = self.data.drop([target_column], axis=1)\n",
    "        self.y = self.data[target_column]\n",
    "\n",
    "    @staticmethod\n",
    "    def log_transform(value):\n",
    "        return np.log(value + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e8437",
   "metadata": {},
   "source": [
    "### Object-Oriented Programming (OOP)\n",
    "Define HousingDataProcessor (derived class)\n",
    "\n",
    "This class inherits from DataProcessor and is specifically designed for housing data.\n",
    "\n",
    "* __init__(self, data_path): Calls the constructor of the parent class DataProcessor using super(). __init__(data_path). It also initializes self.train_data to None.\n",
    "\n",
    "* feature_engineering(self): This method performs feature engineering on the training data:\n",
    "\n",
    "* Combines the features (self.X) and target variable (self.y) into a single dataframe self.train_data.\n",
    "\n",
    "* Applies the log_transform function to the specified columns (total_rooms, total_bedrooms, population, households) to handle skewed distributions.\n",
    "\n",
    "* Creates two new features: bedroom_ratio (ratio of total bedrooms to total rooms) and household_rooms (ratio of total rooms to households).\n",
    "\n",
    "* encode_categorical(self, column): This method encodes a categorical column using one-hot encoding. It takes the column name as input and:\n",
    "\n",
    "* Creates dummy variables using pd.get_dummies for the specified column.\n",
    "\n",
    "* Joins the dummy variables with the train_data dataframe and drops the original categorical column.\n",
    "\n",
    "* feature_importance_generator(self, model): This method generates a generator that yields feature importance values for the given model. It takes a trained model as input and:\n",
    "\n",
    "* Extracts the feature importance values from the model using model.feature_importances_.\n",
    "\n",
    "* Iterates over the feature names and importance values, sorting them in descending order of importance.\n",
    "\n",
    "* Yields a string representation of each feature name and its importance for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b566f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingDataProcessor(DataProcessor):\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__(data_path)\n",
    "        self.train_data = None\n",
    "\n",
    "    def feature_engineering(self):\n",
    "        self.train_data = self.X.join(self.y)\n",
    "        for column in ['total_rooms', 'total_bedrooms', 'population', 'households']:\n",
    "            self.train_data[column] = self.log_transform(self.train_data[column])\n",
    "        self.train_data['bedroom_ratio'] = self.train_data['total_bedrooms'] / self.train_data['total_rooms']\n",
    "        self.train_data['household_rooms'] = self.train_data['total_rooms'] / self.train_data['households']\n",
    "\n",
    "    def encode_categorical(self, column):\n",
    "        self.train_data = self.train_data.join(pd.get_dummies(self.train_data[column])).drop([column], axis=1)\n",
    "\n",
    "    def feature_importance_generator(self, model):\n",
    "        feature_importance = model.feature_importances_\n",
    "        feature_names = self.train_data.drop(['median_house_value'], axis=1).columns\n",
    "        for name, importance in sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True):\n",
    "            yield f\"{name}: {importance:.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c3b6e",
   "metadata": {},
   "source": [
    "### Machine Learning Model\n",
    "\n",
    "* This function trains a Random Forest regression model on the given features (X) and target variable (y).\n",
    "\n",
    "* Splits the data into training and testing sets using train_test_split.\n",
    "\n",
    "* Standardizes the numerical features using StandardScaler to improve model performance.\n",
    "\n",
    "* Creates a Random Forest model with 300 trees and a random state of 42 for reproducibility.\n",
    "\n",
    "* Fits the model on the training data and returns the trained model, scaled testing features, and testing target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cbb5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    return model, X_test_scaled, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc250d5a",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "* Creates an instance of HousingDataProcessor with the CSV file path.\n",
    "\n",
    "* Calls the necessary methods to clean the data, split features and target, perform feature engineering, and encode the categorical column.\n",
    "\n",
    "* Extracts features and target variables for training.\n",
    "\n",
    "* Trains the model using the train_model function.\n",
    "\n",
    "* Prints the feature importance values using the feature_importance_generator method.\n",
    "\n",
    "* Evaluates the model's accuracy on the testing data using model.score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf4214a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/housing.csv\"\n",
    "processor = HousingDataProcessor(path)\n",
    "processor.clean_data()\n",
    "processor.split_features_target('median_house_value')\n",
    "processor.feature_engineering()\n",
    "processor.encode_categorical('ocean_proximity')\n",
    "\n",
    "X = processor.train_data.drop(['median_house_value'], axis=1)\n",
    "y = processor.train_data['median_house_value']\n",
    "model, X_test, y_test = train_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc28b5",
   "metadata": {},
   "source": [
    "### Results & Feature Importance:\n",
    "\n",
    "* median_income: 0.4827\n",
    "This feature has the highest importance, suggesting that the median income of the neighborhood is a strong predictor of housing prices.\n",
    "\n",
    "* INLAND: 0.1423\n",
    "This indicates that the location of the house (inland) is also a significant factor.\n",
    "\n",
    "* longitude: 0.0985\n",
    "The geographic longitude contributes to the prediction, possibly indicating that the location relative to other areas influences prices.\n",
    "\n",
    "* latitude: 0.0888\n",
    "Similar to longitude, the geographic latitude also plays a role in price prediction.\n",
    "\n",
    "* housing_median_age: 0.0477\n",
    "The age of the housing stock in the neighborhood is another important factor.\n",
    "\n",
    "* bedroom_ratio: 0.0317\n",
    "The ratio of bedrooms to total rooms is considered relevant.\n",
    "\n",
    "* population: 0.0276\n",
    "The population density of the area seems to have some influence on prices.\n",
    "\n",
    "* household_rooms: 0.0243\n",
    "The average number of rooms per household is also a contributing factor.\n",
    "\n",
    "* total_rooms: 0.0192\n",
    "The total number of rooms in the neighborhood is less important compared to other features.\n",
    "\n",
    "* total_bedrooms: 0.0140\n",
    "The total number of bedrooms is also less influential.\n",
    "\n",
    "* households: 0.0127\n",
    "The number of households in the neighborhood has a relatively low impact.\n",
    "\n",
    "* NEAR OCEAN: 0.0058\n",
    "Proximity to the ocean is considered a factor, but with a lower importance compared to other features.\n",
    "\n",
    "* ISLAND: 0.0002\n",
    "Being on an island has the least impact on price prediction.\n",
    "\n",
    "### Model Accuracy:\n",
    "\n",
    "The model's accuracy is: 0.8220\n",
    "This statement indicates that the trained Random Forest model achieved an accuracy of 82.20% on the testing dataset. This means that the model correctly predicted the median house value for approximately 82.2% of the houses in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3d4c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "median_income: 0.4827\n",
      "----------\n",
      "INLAND: 0.1423\n",
      "----------\n",
      "longitude: 0.0985\n",
      "----------\n",
      "latitude: 0.0888\n",
      "----------\n",
      "housing_median_age: 0.0477\n",
      "----------\n",
      "bedroom_ratio: 0.0317\n",
      "----------\n",
      "population: 0.0276\n",
      "----------\n",
      "household_rooms: 0.0243\n",
      "----------\n",
      "total_rooms: 0.0192\n",
      "----------\n",
      "total_bedrooms: 0.0140\n",
      "----------\n",
      "households: 0.0127\n",
      "----------\n",
      "NEAR OCEAN: 0.0058\n",
      "----------\n",
      "<1H OCEAN: 0.0033\n",
      "----------\n",
      "NEAR BAY: 0.0012\n",
      "----------\n",
      "ISLAND: 0.0002\n",
      "----------\n",
      "The model's accuracy is: 0.8220\n"
     ]
    }
   ],
   "source": [
    "for importance in processor.feature_importance_generator(model):\n",
    "    print('-'*10)\n",
    "    print(importance)\n",
    "\n",
    "print('-'*10)\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"The model's accuracy is: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projects_PY3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
